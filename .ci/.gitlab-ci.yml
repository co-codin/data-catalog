stages:
  - build
  - test
  - deploy

include:
  - project: "smart-dwh/dwh"
    file: ".ci/helm-semver.yml"
    ref: dev

variables:
  DOCKER_REPO: repo.n3zdrav.ru:18444

build-image:
  stage: build
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  before_script:
    - echo $REGCRED | base64 -d > /kaniko/.docker/config.json
  script:
    - /kaniko/executor --dockerfile=prod.dockerfile --context=dir://. --destination=$DOCKER_REPO/$CI_PROJECT_NAME:$CI_COMMIT_REF_SLUG-$CI_COMMIT_SHORT_SHA --cache=true --cache-repo=$DOCKER_REPO/kaniko-cache --cache-dir=/cache

build-migrations:
  stage: build
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  before_script:
    - echo $REGCRED | base64 -d > /kaniko/.docker/config.json
  script:
    - /kaniko/executor --dockerfile=.ci/Dockerfile.migrations --context=dir://. --destination=$DOCKER_REPO/$CI_PROJECT_NAME-migrations:$CI_COMMIT_REF_SLUG-$CI_COMMIT_SHORT_SHA --cache=true --cache-repo=$DOCKER_REPO/kaniko-cache --cache-dir=/cache

deploy:
  stage: deploy
  image:
    name: alpine/helm:3.11.2
    entrypoint:
      - ""
  environment:
    name: $CI_COMMIT_REF_SLUG
    url: https://$CI_COMMIT_REF_SLUG.smartdwh.k8s.bi.n3zdrav.ru
  rules:
    - if: $CI_COMMIT_REF_PROTECTED == "true" && $CI_PIPELINE_SOURCE != "merge_request_event" 
    - when: never
  retry: 2
  before_script:
    - mkdir -p /root/.kube
    - echo $KUBE_CONFIG | base64 -d > /root/.kube/config
  script:
    - apk add yq
    - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" && chmod +x kubectl && mv kubectl /bin/.
    - export SITE_URL=$(echo -n $CI_ENVIRONMENT_URL | awk -F/ '{gsub(/^https:\/\//, ""); print $1}')
    - path_value=$(printf '/%s(/|$)(.*)' "$CI_PROJECT_NAME")
    - yq eval ".ingress.hosts[0].host = env(SITE_URL) | .ingress.tls[0].hosts[0] = env(SITE_URL) | .ingress.hosts[0].paths[0].path = \"${path_value}\"" .ci/$CI_PROJECT_NAME/values.yaml > .ci/$CI_PROJECT_NAME/updated-values.yaml
    - >
      helm upgrade --install -n smartdwh --timeout 1m 
      --set-string ciEnv="$CI_ENVIRONMENT_NAME" 
      --set-string secrets.encryption_key="$DWH_DATA_CATALOG_ENCRYPTION_KEY_STRING"
      --set-string secrets.db_connection_string="$DB_CONNECTION_STRING/$CI_PROJECT_NAME-$CI_ENVIRONMENT_NAME"
      --set-string secrets.db_migration_connection_string="$DB_MIGRATION_CONNECTION_STRING/$CI_PROJECT_NAME-$CI_ENVIRONMENT_NAME"
      --set-string secrets.mq_connection_string="$MQ_CONN_STRING"
      --set-string secrets.migration_exchange="graph_migration-$CI_ENVIRONMENT_NAME"
      --set-string secrets.migration_request_queue="migration_requests-$CI_ENVIRONMENT_NAME"
      --set-string secrets.migrations_result_queue="migration_results-$CI_ENVIRONMENT_NAME"
      --set-string secrets.publish_exchange="publish_exchange-$CI_ENVIRONMENT_NAME"
      --set-string secrets.publish_request_queue="publish_requests-$CI_ENVIRONMENT_NAME"
      --set-string secrets.publish_result_queue="publish_results-$CI_ENVIRONMENT_NAME"
      --set-string secrets.age_connection_string="$AGE_CONN_STRING-$CI_ENVIRONMENT_NAME"
      --set-string configmap.api_iam="http://iam-$CI_ENVIRONMENT_NAME:8000"
      --set-string configmap.api_task_broker="http://task-broker-$CI_ENVIRONMENT_NAME:8000" 
      --set-string configmap.api_query_executor="http://query-executor-$CI_ENVIRONMENT_NAME:8000" 
      --set image.tag=$CI_COMMIT_REF_SLUG-$CI_COMMIT_SHORT_SHA 
      --set image.repository=$DOCKER_REPO/$CI_PROJECT_NAME 
      --set-string 'podAnnotations.instrumentation\.opentelemetry\.io/inject-python=false'
      $CI_PROJECT_NAME-$CI_ENVIRONMENT_NAME ./.ci/$CI_PROJECT_NAME -f .ci/$CI_PROJECT_NAME/updated-values.yaml
    - DEPLOYMENT_ROLLOUT_STATUS=$(kubectl rollout status -n smartdwh deployment/$CI_PROJECT_NAME-$CI_ENVIRONMENT_NAME 2>&1)
    - DEPLOYMENT_ROLLOUT_SUCCESS=$?
    - |
      if [ $DEPLOYMENT_ROLLOUT_SUCCESS -ne 0 ]; 
        then echo "$DEPLOYMENT_ROLLOUT_STATUS" && echo "Rolling back..." \
        && kubectl get pods -n smartdwh \
        && kubectl describe po -n smartdwh -l app="$CI_PROJECT_NAME-$CI_ENVIRONMENT_NAME" \
        && FAILED_POD=$(kubectl get pods -n smartdwh -l app="$CI_PROJECT_NAME-$CI_ENVIRONMENT_NAME" --field-selector status.phase!=Running -o jsonpath="{.items[0].metadata.name}") \
        && kubectl logs -n smartdwh "$FAILED_POD" \
        && helm rollback $CI_PROJECT_NAME-$CI_ENVIRONMENT_NAME \
        && exit 1; 
      fi
